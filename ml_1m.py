# -*- coding: utf-8 -*-
"""ml_1m (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10xo72Pw_YcUM1at78_DJoJ1vEktKl0nF

# My code

بارگیری فایل دیتاست از آدرس معرفی شده
"""

!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip

"""باز کردن فایل مذکور از حالت فشرده"""

!unzip ml-1m.zip

"""فراخوانی کتابخانه ها - پکیج ها و توابع لازم"""

import numpy as np
from collections import defaultdict
from sklearn.model_selection import train_test_split

data_path = 'ml-1m/ratings.dat'
n_users = 6040
n_movies = 3706

"""<div dir=rtl>
خواندن فایل rating مربوط به نظرات کاربران در مورد فیلم ها (آی دی کاربر - آی دی فیلم - نمره ی داده شده)
"""

# UserID::MovieID::Rating
data_path = 'ml-1m/ratings.dat'
rate_data = []
with open(data_path, 'r') as file:
  for line in file.readlines():
    # print(line)
    user_id, movie_id, rating, _ = line.split("::")
    rating = int(rating)
    user_id = int(user_id)
    movie_id = int(movie_id)
    rate_data.append([user_id, movie_id, rating])

print(rate_data[:10])
total_rating_record = len(rate_data)
print("total_rating_record: " + str(total_rating_record))

"""<div dir=rtl>
خواندن فایل movies مربوط به اطلاعات فیلم ها (آی دی - عنوان - ژانر)

"""

# MovieID::Title::Genres
data_path = 'ml-1m/movies.dat'
movie_data = []
with open(data_path, 'r', encoding = "ISO-8859-1") as file:
  for line in file.readlines():
    movie_id, title, genres = line.split("::")
    movie_id = int(movie_id)
    genres = genres.split('\n')[0]
    movie_data.append([movie_id, title, genres])

print(movie_data[:10])
print(len(movie_data))
max_movie_id = max(movie_data)[0] #جهت دريافت بزرگترين آي. دي از ديتا ست فيلم ها
print(max(movie_data))
print(max_movie_id)

"""تنظیم کردن آی دی فیلم با اندیس آرایه"""

movie_data_2 = [i for i in range(max_movie_id)]
for i in movie_data:
  index = i[0]
  movie_data_2[index-1] = i

print(movie_data_2[:10])
print(movie_data_2[-1])

"""<div dir=rtl>
خواندن فایل users مربوط به اطلاعات کاربران (آی دی کاربر - جنسیت - سن - شغل - کدپستی)
"""

# UserID::Gender::Age::Occupation::Zip-code
data_path = 'ml-1m/users.dat'
user_data = []
with open(data_path, 'r') as file:
  for line in file.readlines():
    # print(line)
    user_id, gender, age, occupation, zip_code = line.split("::")
    user_id = int(user_id)
    age = int(age)
    zip_code = zip_code.split("\n")[0]
    user_data.append([user_id, gender, age, occupation, zip_code])

print(user_data[:10])
print(len(user_data))
print(max(user_data))

"""ایجاد یک ليست جدید برای ايجاد رابطه كليه ي اطلاعات"""

collective_data = []
collective_data = rate_data.copy()
print(collective_data[:10])

print(user_data[0])

"""افزودن اطلاعات کاربران و فیلم ها به دیتاست نظرات

پس از اجرای این بخش -در کنار هر نظر- مشخصات فرد نظر دهنده و همچنین ژانر فیلم نیز افزوده می گردد
"""

collective_data = []
collective_data = rate_data.copy()
print(collective_data[:10])

#َافزودن اطلاعات كاربران به جدول ارزيابي
for i in range(len(collective_data)):
# for i in range(10):
  user_id = rate_data[i][0]
  # print(user_id)
  movie_id = rate_data[i][1]
  # print(movie_id)
  rating = rate_data[i][2]
  # print(rating)

  ############## all features selected from user data (remove zip_code col)
  temp = user_data[user_id - 1][:4].copy()
  #######################################

  # print(1)
  # print(temp)
  temp.append(movie_id)
  # print(2)
  # print(temp)
  temp.append(rating)
  # print(3)
  # print(temp)
  collective_data[i] = temp

print(collective_data[:10])

#َافزودن اطلاعات ويدئوها به جدول ارزيابي
for i in range(len(collective_data)):
# for i in range(10):
  ######## all features selected from user data + movie_id
  temp = collective_data[i][:5]
  ###########################################
  # print(temp)
  movie_id = collective_data[i][4]  ####################
  # print(movie_id)
  rating = collective_data[i][5]  #####################
  # print(rating)
  genres = movie_data_2[movie_id - 1][2]  ########### feature selected genres
  temp.append(genres)
  temp.append(rating)

  collective_data[i] = temp

print(collective_data[:10])
#UserID::Gender::Age::Occupation::MovieID::Genres::Rating

"""تقسیم کردن داده ها به دو بخش داده های آموزش مدل و داده‌های تست و ارزيابي مدل

 مطابق معمول این دو به نسبت ۸۰-۲۰ تقسیم شده اند.
"""

collective_data_train, collective_data_test = train_test_split(collective_data,
                                                    test_size=0.2,
                                                    random_state=80)
#Using from sklearn.model_selection import train_test_split
# معمولا داده ها را به دوقسمت آموزش و تست تقسيم مي كنيم
# نسبت در اين  بخش
# 0.8 آموزش
# 0.2 تست

# با داده آموزش مدل را آموزش مي دهيم
# با داده تست مدل را ارزيابي مي كنيم

print(collective_data_train[:10])
print("Training data length:")
print(len(collective_data_train))

print(collective_data_test[:10])
print("Test data length:")
print(len(collective_data_test))

""" شمارش نظرات کاربران به نسبت علاقه مندی یا عدم علاقه مندی به فیلم ها"""

# find repeated user ID
# باتوجه به اينكه در محاسبات نايو بيز به 3 داده ذيل احتياج داريم آنها را در ديكشنري نگهداري مي كنيم
user_id_count = {}
count = 0
print(user_id_count)
for i in collective_data_train:
  # i[0]=> UserId
  if i[0] not in user_id_count:  ##########
    user_id_count[i[0]] = {'count':1, 'y':0 , 'n':0}  ###############
  else:
    user_id_count[i[0]]['count'] = user_id_count[i[0]]['count'] + 1  ##########
    count += 1

  # i[6]=> rate
  if i[6] >= 4:
    user_id_count[i[0]]['y'] = user_id_count[i[0]]['y'] + 1  ##################
  else:
    user_id_count[i[0]]['n'] = user_id_count[i[0]]['n'] + 1  ##################

print(user_id_count)
print("User count:"+ str(len(user_id_count)))

"""شمارش کاربران به نسبت علاقه مندی یا عدم علاقه مندی به فیلم ها"""

# find repeated gender
gender_count = {}
count = 0
print(gender_count)
for i in collective_data_train:
  # i[1]=> User Gender
  if i[1] not in gender_count:  ##########
    gender_count[i[1]] = {'count':1, 'y':0 , 'n':0}  ###############
  else:
    gender_count[i[1]]['count'] = gender_count[i[1]]['count'] + 1  ###########
    count += 1

  # i[6]=> rate
  if i[6] >= 4:
    gender_count[i[1]]['y'] = gender_count[i[1]]['y'] + 1  ##################
  else:
    gender_count[i[1]]['n'] = gender_count[i[1]]['n'] + 1  ##################


print("Gender dict:")
print(count)
print(gender_count)
print("Gender type count:")
print(len(gender_count))

"""شمارش سن کاربران به نسبت علاقه مندی یا عدم علاقه مندی به فیلم ها"""

# find repeated Age
age_count = {}
count = 0
print(age_count)
for i in collective_data_train:
  # i[2]=> User Age
  if i[2] not in age_count:  ##########
    age_count[i[2]] = {'count':1, 'y':0 , 'n':0}  ###############
  else:
    age_count[i[2]]['count'] = age_count[i[2]]['count'] + 1  ###############
    count += 1

  # i[6]=> rate
  if i[6] >= 4:
    age_count[i[2]]['y'] = age_count[i[2]]['y'] + 1  ##################
  else:
    age_count[i[2]]['n'] = age_count[i[2]]['n'] + 1  ##################



print("Age dict:")
print(count)
print(age_count)
print("Age type count:")
print(len(age_count))

"""شمارش شغل کاربران به نسبت علاقه مندی یا عدم علاقه مندی به فیلم ها"""

# find repeated occupation
occupation_count = {}
count = 0
print(occupation_count)
for i in collective_data_train:
  # i[3]=> User Occupation
  if i[3] not in occupation_count:  ##########
    occupation_count[i[3]] = {'count':1, 'y':0 , 'n':0}  ###############
  else:
    occupation_count[i[3]]['count'] = occupation_count[i[3]]['count'] + 1  ####
    count += 1

  # i[6]=> rate
  if i[6] >= 4:
    occupation_count[i[3]]['y'] = occupation_count[i[3]]['y'] + 1  ###########
  else:
    occupation_count[i[3]]['n'] = occupation_count[i[3]]['n'] + 1  ###########


print("occupation dict:")
print(count)
print(occupation_count)
print("occupation count:")
print(len(occupation_count))

"""شمارش کاربران به نسبت علاقه مندی یا عدم علاقه مندی به هر فیلم"""

# find repeated movie ID
movie_id_count = {}
count = 0
print(movie_id_count)
for i in collective_data_train:
  # i[4]=> movieId
  if i[4] not in movie_id_count:  ##########
    movie_id_count[i[4]] = {'count':1, 'y':0 , 'n':0}  ###############
  else:
    movie_id_count[i[4]]['count']  = movie_id_count[i[4]]['count']  + 1  ######
    count += 1

  # i[6]=> rate
  if i[6] >= 4:
    movie_id_count[i[4]]['y'] = movie_id_count[i[4]]['y'] + 1  ###########
  else:
    movie_id_count[i[4]]['n'] = movie_id_count[i[4]]['n'] + 1  ###########


print("Reapeted movie ID count:")
print(count)
print(movie_id_count)
print("Movies count:")
print(len(movie_id_count))

"""شمارش کاربران به نسبت علاقه مندی یا عدم علاقه مندی به ژانر ها


"""

# find repeated genres
genres_count = {}
count = 0
print(genres_count)
for i in collective_data_train:

  # i[5]=> movieGenres
  if i[5] not in genres_count:  ##########
    genres_count[i[5]] = {'count':1, 'y':0 , 'n':0}  ###############
  else:
    genres_count[i[5]]['count'] = genres_count[i[5]]['count'] + 1  ############

  # i[6]=> rate
  if i[6] >= 4:
    genres_count[i[5]]['y'] = genres_count[i[5]]['y'] + 1  ##################
  else:
    genres_count[i[5]]['n'] = genres_count[i[5]]['n'] + 1  ##################

    count += 1

print("Reapeted genres count:")
print(count)
print(genres_count)
print("Genres type count:")
print(len(genres_count))

# # find repeated genres
# s = set()
# count = 0
# print(s)
# for i in collective_data_train:
#   if i[5] not in s:  ##########
#     s.add(i[5])
#   else:
#     count += 1


# print("Reapeted genres count:")
# print(count)

"""شمارش نظرات کاربران به نسبت علاقه مندی یا عدم علاقه مندی به فیلم ها"""

# find repeated Rating
rating_count = {}
count = 0
print(rating_count)
for i in collective_data_train:

  # i[6]=> rate
  if i[6] not in rating_count:  ##########
    rating_count[i[6]] = 1  ###############
  else:
    rating_count[i[6]] = rating_count[i[6]] + 1  ###################
    count += 1

print("Rating dict:")
print(count)
print(rating_count)
print("Rating type count:")
print(len(rating_count))

"""نمایش داده های بدست آمده تا کنون"""

#UserID::Gender::Age::Occupation::MovieID::Genres::Rating
#UserID=i[0]::Gender=i[1]::Age=i[2]::Occupation=i[3]::MovieId=i[4]::Genres=i[5]::Rating=i[6]
print(collective_data[:10])
print(collective_data_test[:10])
print(collective_data_train[:10])

"""محاسبه ی تعداد فیلم های مورد علاقه و غیر مورد علاقه توسط نظرات کاربران"""

y_n_rate = {}
y_n_rate['Y'] = rating_count[5] + rating_count[4]
y_n_rate['N'] = rating_count[3] + rating_count[2] + rating_count[1]
y_n_rate['T'] = y_n_rate['Y'] + y_n_rate['N']
# y_n_rate['Y/T'] = y_n_rate['Y'] / y_n_rate['T']
# y_n_rate['N/T'] = y_n_rate['N'] / y_n_rate['T']

print(y_n_rate)

"""محاسبه ی قسمت های مختلف فرمول

و در نهایت قضاوت در مورد میزان دقت مدل
"""

total_test_data_count = 0
successful_test_data_count = 0
failure_test_data_count = 0
for i in collective_data_test:
  total_test_data_count += 1

  # Yes
  p1 = (user_id_count[i[0]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  p2 = (gender_count[i[1]]['y'] + 1) /  (y_n_rate['Y']+ 2)
  p3 = (age_count[i[2]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  p4 = (occupation_count[i[3]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  try:
    p5 = (movie_id_count[i[4]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  except:
    p5 = 1/2
  p6 = (genres_count[i[5]]['y'] + 1) /  (y_n_rate['Y'] + 2)

  p_yes = (y_n_rate['Y']) /  (y_n_rate['T'])

  p_x_yes = p1*p2*p3*p4*p5*p6*p_yes




  # NO
  p1 = (user_id_count[i[0]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  p2 = (gender_count[i[1]]['y'] + 1) /  (y_n_rate['Y']+ 2)
  p3 = (age_count[i[2]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  p4 = (occupation_count[i[3]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  try:
    p5 = (movie_id_count[i[4]]['y'] + 1) /  (y_n_rate['Y'] + 2)
  except:
    p5 = 1/2
  p6 = (genres_count[i[5]]['y'] + 1) /  (y_n_rate['Y'] + 2)

  p_no = (y_n_rate['N']) /  (y_n_rate['T'])

  p_x_no = p1*p2*p3*p4*p5*p6*p_no



  p1 =  (user_id_count[i[0]]['count'] + 1) / (total_rating_record + 2)
  p2 =  (gender_count[i[1]]['count'] + 1) / (total_rating_record + 2)
  p3 =  (age_count[i[2]]['count'] + 1) / (total_rating_record + 2)
  p4 =  (occupation_count[i[3]]['count'] + 1) / (total_rating_record + 2)
  try:
    p5 =  (movie_id_count[i[4]]['count'] + 1) / (total_rating_record + 2)
  except:
    p5 = 1/(total_rating_record + 2)
  p6 =  (genres_count[i[5]]['count'] + 1) / (total_rating_record + 2)

  p_x = p1*p2*p3*p4*p5*p6


  p_no_x = p_x_no * p_no / p_x

  p_yes_x = p_x_yes * p_yes / p_x

  # if total_test_data_count < 100:
  #   print(str(total_test_data_count)+": P yes=" + str(p_yes_x))
  #   print(str(total_test_data_count)+": P no=" + str(p_no_x))

  if p_yes_x > p_no_x:
    if i[6] >= 4:
      successful_test_data_count += 1
    else:
      failure_test_data_count += 1
  elif p_yes_x <= p_no_x:
    if i[6]< 4:
      successful_test_data_count += 1
    else:
      failure_test_data_count += 1

print("Successful prediction count:")
print(successful_test_data_count)
print("Failure prediction count:")
print(failure_test_data_count)
print("Model accuarity:")
print(successful_test_data_count / total_test_data_count)

print(list2[:10])

"""# Book code"""

def load_rating_data(data_path, n_users, n_movies):
  """
  Load rating data from file and also return the number of
    ratings for each movie and movie_id index mapping
  @param data_path: path of the rating data file
  @param n_users: number of users
  @param n_movies: number of movies that have ratings
  @return: rating data in the numpy array of [user, movie];
        movie_n_rating, {movie_id: number of ratings};
        movie_id_mapping, {movie_id: column index in
        rating data}
  """
  data = np.zeros([n_users, n_movies], dtype=np.float32)
  movie_id_mapping = {}
  movie_n_rating = defaultdict(int)
  with open(data_path, 'r') as file:
    for line in file.readlines()[1:]:
      user_id, movie_id, rating, _ = line.split("::")
      user_id = int(user_id) - 1
      if movie_id not in movie_id_mapping:
        movie_id_mapping[movie_id] = len(movie_id_mapping)
      rating = int(rating)
      data[user_id, movie_id_mapping[movie_id]] = rating

      if rating > 0:
          movie_n_rating[movie_id] += 1
  return data, movie_n_rating, movie_id_mapping

data, movie_n_rating, movie_id_mapping = load_rating_data(data_path, n_users, n_movies)

def display_distribution(data):
  values, counts = np.unique(data, return_counts=True)
  for value, count in zip(values, counts):
    print(f'Number of rating {int(value)}: {count}')

display_distribution(data)

movie_id_most, n_rating_most = sorted(movie_n_rating.items(),
                                      key=lambda d: d[1], reverse=True)[0]
print(f'Movie ID {movie_id_most} has {n_rating_most} ratings.')

X_raw = np.delete(data, movie_id_mapping[movie_id_most], axis=1)
Y_raw = data[:, movie_id_mapping[movie_id_most]]

X = X_raw[Y_raw > 0]
Y = Y_raw[Y_raw > 0]
print('Shape of X:', X.shape)

print('Shape of Y:', Y.shape)

display_distribution(Y)

recommend = 3
Y[Y <= recommend] = 0
Y[Y > recommend] = 1
n_pos = (Y == 1).sum()
n_neg = (Y == 0).sum()
print(f'{n_pos} positive samples and {n_neg} negative samples.')

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,
                                                    random_state=42)

print(len(Y_train), len(Y_test))

from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB(alpha=1.0, fit_prior=True)
clf.fit(X_train, Y_train)

prediction_prob = clf.predict_proba(X_test)
print(prediction_prob[0:10])

prediction = clf.predict(X_test)
print(prediction[:10])

accuracy = clf.score(X_test, Y_test)
print(f'The accuracy is: {accuracy*100:.1f}%')



"""# Trash!"""

# find repeated Zip-code count
s = set()
# s = []
count = 0
# print(s)
for i in collective_data:
  # print(i[6])
  if i[6] not in s:
    s.add(i[6])
    # s.append([i[6],1])
  else:
    count += 1

print("Reapeted Zip-code count:")
print(count)
print(s)
print(len(s))

# find repeated Zip-code
zip_code_count = {}
count = 0
print(zip_code_count)
for i in collective_data:
  if i[4] not in zip_code_count:  ##########
    zip_code_count[i[4]] = 1  ###############
  else:
    zip_code_count[i[4]] = zip_code_count[i[4]] + 1  ###################
    count += 1

print("Reapeted Zip-code count:")
print(count)
print(zip_code_count)
print(len(zip_code_count))

# p1 = (user_id_count[i[0]]['y'] + 1) /  (user_id_count[i[0]]['count'] + 2)
  # p2 = (gender_count[i[1]]['y'] + 1) /  (gender_count[i[1]]['count'] + 2)
  # p3 = (age_count[i[2]]['y'] + 1) /  (age_count[i[2]]['count'] + 2)
  # p4 = (occupation_count[i[3]]['y'] + 1) /  (occupation_count[i[3]]['count'] + 2)
  # try:
  #   p5 = (movie_id_count[i[4]]['y'] + 1) /  (movie_id_count[i[4]]['count'] + 2)
  # except:
  #   p5 = 1/2
  # p6 = (genres_count[i[5]]['y'] + 1) /  (genres_count[i[5]]['count'] + 2)

# # find repeated Zip-code count
# s = set()
# count = 0
# # print(s)
# for i in user_data:
#   if i[4] not in s:  #############
#     s.add(i[4])  ######################
#   else:
#     count += 1

# print("Reapeted Zip-code count:")
# print(count)